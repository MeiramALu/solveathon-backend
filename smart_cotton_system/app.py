import streamlit as st
import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
import cv2
from PIL import Image, ImageOps
import os

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(
    page_title="Cotton AI Platform",
    page_icon="üåæ",
    layout="wide"
)

# --- CSS –î–õ–Ø –ö–†–ê–°–û–¢–´ (–ó–µ–ª–µ–Ω–∞—è —Ç–µ–º–∞) ---
st.markdown("""
    <style>
    .main {
        background-color: #f5fdf5;
    }
    .stButton>button {
        background-color: #2e7d32;
        color: white;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("üåæ Cotton Quality Control & Analytics AI")
st.markdown("–ï–¥–∏–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ö–ª–æ–ø–∫–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –ø–æ–¥–±–æ—Ä–∞ —Å–µ–º—è–Ω.")

# --- –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô (–ö–≠–®–ò–†–û–í–ê–ù–ò–ï) ---
@st.cache_resource
def load_hvi_models():
    try:
        model = joblib.load('models/cotton_xgboost_model.pkl')
        scaler = joblib.load('models/cotton_scaler.pkl')
        enc = joblib.load('models/color_encoder.pkl')
        return model, scaler, enc
    except:
        return None, None, None

@st.cache_resource
def load_cv_model():
    try:
        return tf.keras.models.load_model('models/cotton_model.keras')
    except:
        return None

@st.cache_resource
def load_seed_models():
    try:
        m_yield = joblib.load('models/yield_model.pkl')
        m_qual = joblib.load('models/quality_model.pkl')
        le_loc = joblib.load('models/loc_encoder.pkl')
        le_var = joblib.load('models/var_encoder.pkl')
        return m_yield, m_qual, le_loc, le_var
    except:
        return None, None, None, None

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—ë –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
hvi_model, hvi_scaler, hvi_enc = load_hvi_models()
cv_model = load_cv_model()
seed_yield, seed_qual, seed_loc, seed_var = load_seed_models()

# --- –í–ö–õ–ê–î–ö–ò ---
tab1, tab2, tab3 = st.tabs(["üìä 1. HVI –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è", "üì∑ 2. –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ", "üå± 3. –ü–æ–¥–±–æ—Ä –°–µ–º—è–Ω"])

# ==========================================
# TAB 1: HVI CLASSIFICATION
# ==========================================
with tab1:
    st.header("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ–ª–æ–∫–Ω–∞ (HVI)")
    
    if hvi_model is None:
        st.error("–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª–∏ HVI –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ models/")
    else:
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –≤–≤–æ–¥–∞
        input_method = st.radio("–°–ø–æ—Å–æ–± –≤–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö:", ["–í—Ä—É—á–Ω—É—é", "–ó–∞–≥—Ä—É–∑–∫–∞ CSV"])
        
        if input_method == "–í—Ä—É—á–Ω—É—é":
            col1, col2, col3 = st.columns(3)
            with col1:
                mic = st.number_input("Micronaire (–¢–æ–Ω–∏–Ω–∞)", 2.0, 6.0, 4.0)
                strength = st.number_input("Strength (–ü—Ä–æ—á–Ω–æ—Å—Ç—å)", 20.0, 40.0, 30.0)
                length = st.number_input("Length (–î–ª–∏–Ω–∞)", 0.9, 1.3, 1.12)
            with col2:
                uniformity = st.number_input("Uniformity (%)", 70.0, 90.0, 83.0)
                trash_grade = st.selectbox("Trash Grade", [1, 2, 3, 4, 5, 6, 7])
                color_grade = st.selectbox("Color Grade", ['11-1', '21-2', '31-3', '41-4', '51-5']) # –î–æ–±–∞–≤—å —Å–≤–æ–∏ —Ü–≤–µ—Ç–∞
            with col3:
                trash_cnt = st.number_input("Trash Count", 0, 100, 15)
                trash_area = st.number_input("Trash Area", 0.0, 5.0, 0.2)
                sfi = st.number_input("SFI", 0.0, 20.0, 9.0)
                sci = st.number_input("SCI", 0.0, 200.0, 130.0)
            
            if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–∑–µ—Ü"):
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                input_data = pd.DataFrame([{
                    'Micronaire': mic, 'Strength': strength, 'Length': length,
                    'Uniformity': uniformity, 'Trash_Grade': trash_grade,
                    'Trash_Cnt': trash_cnt, 'Trash_Area': trash_area,
                    'SFI': sfi, 'SCI': sci, 'Color_Grade': color_grade
                }])
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞
                try:
                    input_data['Color_Grade'] = hvi_enc.transform(input_data['Color_Grade'])
                    input_data = hvi_scaler.transform(input_data)
                    
                    pred = hvi_model.predict(input_data)[0]
                    probs = hvi_model.predict_proba(input_data)[0]
                    
                    classes = {0: 'Low Grade (–ë—Ä–∞–∫) üî¥', 1: 'Premium (–í—ã—Å—à–∏–π) üü¢', 2: 'Standard (–°—Ä–µ–¥–Ω–∏–π) üü°'}
                    
                    st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {classes[pred]}")
                    st.progress(int(probs[pred]*100))
                    st.write(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ò–ò: {probs[pred]*100:.1f}%")
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")

        else:
            uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ HVI", type="csv")
            if uploaded_file:
                st.info("–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.")
                # –¢—É—Ç –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è —á—Ç–µ–Ω–∏—è CSV –∏ predict –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫

# ==========================================
# TAB 2: COMPUTER VISION
# ==========================================
with tab2:
    st.header("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã —Ö–ª–æ–ø–∫–∞ –ø–æ —Ñ–æ—Ç–æ")
    
    if cv_model is None:
        st.error("–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å CV (.keras) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    else:
        uploaded_img = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —Ö–ª–æ–ø–∫–∞", type=["jpg", "png", "jpeg"])
        
        if uploaded_img:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–æ—Ç–æ
            image = Image.open(uploaded_img).convert('RGB')
            st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ", width=300)
            
            if st.button("üì∑ –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"):
                # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ (–∫–∞–∫ –≤ —Ç–≤–æ–µ–º —Å–∫—Ä–∏–ø—Ç–µ)
                img_array = np.array(image)
                # OpenCV resize (—á—Ç–æ–±—ã —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–ª–æ —Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–æ–π)
                img_resized = cv2.resize(img_array, (224, 224))
                img_batch = np.expand_dims(img_resized, 0) # (1, 224, 224, 3)
                
                # –ü—Ä–µ–¥–∏–∫—Ç
                prediction = cv_model.predict(img_batch)
                score = prediction[0][0]
                
                # –õ–æ–≥–∏–∫–∞: 0 - Clean, 1 - Dirty
                if score > 0.5:
                    label = "–ì–†–Ø–ó–ù–´–ô (Dirty) üçÇ"
                    conf = score
                    color = "red"
                else:
                    label = "–ß–ò–°–¢–´–ô (Clean) ‚ú®"
                    conf = 1 - score
                    color = "green"
                
                st.markdown(f"<h2 style='color:{color};'>{label}</h2>", unsafe_allow_html=True)
                st.write(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {conf*100:.2f}%")

# ==========================================
# TAB 3: SEED RECOMMENDATION
# ==========================================
with tab3:
    st.header("–£–º–Ω—ã–π –ø–æ–¥–±–æ—Ä —Å–µ–º—è–Ω (Yield Prediction)")
    
    if seed_yield is None:
        st.error("–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª–∏ —Å–µ–º—è–Ω (.pkl) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
    else:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ª–æ–∫–∞—Ü–∏–π –∏–∑ —ç–Ω–∫–æ–¥–µ—Ä–∞
        locations = seed_loc.classes_
        selected_loc = st.selectbox("üìç –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω/–ø–æ–ª–µ:", locations)
        
        # –°–ª–æ–≤–∞—Ä—å –æ–ø–∏—Å–∞–Ω–∏–π (–∏–∑ —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞)
        varieties_info = {
            'PHY 485WRF': {'type': 'Upland', 'brand': 'PhytoGen (Corteva)'},
            'DP 555 R/R': {'type': 'Upland', 'brand': 'DeltaPine (Monsanto)'},
            'FM 960B2R': {'type': 'Upland', 'brand': 'FiberMax (Bayer)'},
            'STV 4892 BR': {'type': 'Upland', 'brand': 'Stoneville'},
            'DPL 445BR': {'type': 'Upland', 'brand': 'DeltaPine'},
            'TAMCOT 22': {'type': 'Upland', 'brand': 'Tamcot (Texas A&M)'},
            'COBALT': {'type': 'Pima', 'brand': 'Cobalt Pima (Premium)'},
            'DP 340': {'type': 'Pima', 'brand': 'DeltaPine Pima'},
            'PHY 800': {'type': 'Pima', 'brand': 'PhytoGen Pima'}
        }

        if st.button("üå± –ü–æ–¥–æ–±—Ä–∞—Ç—å –ª—É—á—à–∏–µ —Å–µ–º–µ–Ω–∞"):
            loc_code = seed_loc.transform([selected_loc])[0]
            all_vars = seed_var.classes_
            
            results = []
            for var_name in all_vars:
                var_code = seed_var.transform([var_name])[0]
                
                # –ü—Ä–µ–¥–∏–∫—Ç
                pred_y = seed_yield.predict([[loc_code, var_code]])[0]
                pred_str = seed_qual.predict([[loc_code, var_code]])[0]
                
                # –ò–Ω—Ñ–æ
                info = varieties_info.get(var_name, {'type': '-', 'brand': 'Local'})
                price_mul = 1.3 if info['type'] == 'Pima' else 1.0
                score = (pred_y * price_mul) + (pred_str * 5)
                
                results.append({
                    '–°–æ—Ä—Ç': var_name,
                    '–¢–∏–ø': info['type'],
                    '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å': info['brand'],
                    '–ü—Ä–æ–≥–Ω–æ–∑ —É—Ä–æ–∂–∞—è (lb/ac)': int(pred_y),
                    '–ö–∞—á–µ—Å—Ç–≤–æ (g/tex)': round(pred_str, 1),
                    'Score': score
                })
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–≤–æ–¥
            results.sort(key=lambda x: x['Score'], reverse=True)
            top3 = results[:3]
            
            st.success(f"–¢–æ–ø-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è {selected_loc}:")
            
            # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –∫–∞—Ä—Ç–æ—á–∫–∞–º–∏
            for i, rec in enumerate(top3):
                with st.container():
                    st.markdown(f"### üèÜ #{i+1} {rec['–°–æ—Ä—Ç']}")
                    c1, c2, c3 = st.columns(3)
                    c1.metric("–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å", f"{rec['–ü—Ä–æ–≥–Ω–æ–∑ —É—Ä–æ–∂–∞—è (lb/ac)']} lb/ac")
                    c2.metric("–ö–∞—á–µ—Å—Ç–≤–æ", f"{rec['–ö–∞—á–µ—Å—Ç–≤–æ (g/tex)']}")
                    c3.write(f"**{rec['–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å']}**")
                    st.divider()

# --- FOOTER ---
st.markdown("---")
st.caption("üöÄ –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–ª—è –•–∞–∫–∞—Ç–æ–Ω–∞ 2025 | Powered by XGBoost, TensorFlow & Scikit-Learn")